{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uNVxyyI1I1_h"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLK60gw9qjof"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_boston\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "lr = 10 ** -6"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neural Network individual components:"
      ],
      "metadata": {
        "id": "NgPmmeUAF1FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# matrix multiplication XW\n",
        "\n",
        "class matrix_multiplication_layer:\n",
        "  def __init__(self, neurons_count, features_count):\n",
        "    self. X = np.array([])\n",
        "    self.W = np.array([[0 for j in range(neurons_count)] for i in range(features_count)])\n",
        "\n",
        "  def forward_pass(self, X):\n",
        "    self.X = X\n",
        "    # N = XW\n",
        "    N = np.dot(self.X, self.W)\n",
        "    return N\n",
        "\n",
        "  def backward_pass(self, dL_dN):\n",
        "    #dL_dW\n",
        "    dL_dW = np.dot(self.X.T, dL_dN)\n",
        "    self.W = self.W - (lr * dL_dW)\n",
        "\n",
        "    #dL_dX\n",
        "    dL_dX = np.dot(dL_dN, self.W.T)\n",
        "    return dL_dX"
      ],
      "metadata": {
        "id": "-IBUhtBuxvRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bias addition layer\n",
        "\n",
        "class bias_addition_layer:\n",
        "  def __init__(self, neurons_count):\n",
        "    self.N = np.array([])\n",
        "    self.B = np.array([0 for i in range(neurons_count)])\n",
        "\n",
        "  def forward_pass(self, N):\n",
        "    self.N = N\n",
        "    Z = self.N + self.B\n",
        "    return Z\n",
        "\n",
        "  def backward_pass(self, dL_dZ):\n",
        "    #dL_dB\n",
        "    dL_dB = dL_dZ.sum(axis = 0) # column wise summation\n",
        "    self.B = self.B - (lr * dL_dB)\n",
        "\n",
        "    #dL_dN\n",
        "    dL_dN = dL_dZ\n",
        "    return dL_dN"
      ],
      "metadata": {
        "id": "fXu9ZAG4xonQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mean squared loss\n",
        "\n",
        "class mse_layer:\n",
        "  def __init__(self):\n",
        "    self.P = np.array([]) # predicted values\n",
        "    self.Y = np.array([]) # actual values\n",
        "\n",
        "  def forward_pass(self, P, Y):\n",
        "    self.P = P\n",
        "    self.Y = Y\n",
        "    mse = np.dot((self.P - self.Y).T, self.P - self.Y)\n",
        "    return mse\n",
        "\n",
        "  def backward_pass(self):\n",
        "    dL_dP = self.P - self.Y\n",
        "    return dL_dP"
      ],
      "metadata": {
        "id": "F1hTtnYOxozG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax layer\n",
        "\n",
        "class softmax_layer:\n",
        "  def __init__(self):\n",
        "    self.Z = np.array([])\n",
        "    self.softmax = np.array([])\n",
        "\n",
        "  def forward_pass(self, Z):\n",
        "    self.Z = Z\n",
        "    self.softmax = np.exp(Z)\n",
        "    row_sum_of_exponentials = np.array([[i] for i in self.softmax.sum(axis = 1)])\n",
        "    self.softmax = self.softmax / row_sum_of_exponentials\n",
        "    return self.softmax\n",
        "\n",
        "  def backward_pass(self, dL_dSoftmax):\n",
        "    dL_dZ = []\n",
        "    for i in range(len(dL_dSoftmax)):\n",
        "        cols = len(self.Z[0])\n",
        "        A = np.zeros([cols, cols])\n",
        "        S = self.softmax\n",
        "\n",
        "        for j in range(cols):\n",
        "            for k in range(cols):\n",
        "                if j == k:\n",
        "                    A[j][k] = S[i][j]*(1-S[i][k])\n",
        "                else:\n",
        "                    A[j][k] = -S[i][j]*S[i][k]\n",
        "                    \n",
        "        dL_dZ.append(np.dot(dL_dSoftmax[i], A))\n",
        "    return np.array(dL_dZ)"
      ],
      "metadata": {
        "id": "cC9CIUVAxo6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sigmoid layer\n",
        "\n",
        "class sigmoid_layer:\n",
        "  def __init__(self):\n",
        "    self.Z = np.array([]) # Z = N + B\n",
        "    self.sigmoid = np.array([])\n",
        "\n",
        "  def forward_pass(self, Z):\n",
        "    self.Z = Z\n",
        "    self.sigmoid = np.exp(-1 * Z)\n",
        "    self.sigmoid = 1 / 1 + self.sigmoid\n",
        "    return self.sigmoid\n",
        "\n",
        "  def backward_pass(self, dL_dSigmoid):\n",
        "    #Z = N + B\n",
        "    dL_dZ = self.sigmoid * (1 - self.sigmoid) * dL_dSigmoid\n",
        "    return dL_dZ"
      ],
      "metadata": {
        "id": "OFpWiEaSxpE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cross entropy loss layer\n",
        "\n",
        "class cross_entropy_loss_layer:\n",
        "  def __init__(self):\n",
        "    self.P = np.array([]) #predictions\n",
        "    self.Y = np.array([]) #actual labels\n",
        "\n",
        "  def forward_pass(self, P, Y):\n",
        "    self.P = P\n",
        "    self.Y = Y\n",
        "    # finding loss for each row and then adding the lossed of all the rows\n",
        "    cross_entropy_loss = (-1 * Y * np.log(P)).sum(axis = 1).sum(axis = 0)\n",
        "    return np.array([[cross_entropy_loss]])\n",
        "\n",
        "  def backward_pass(self):\n",
        "    #dL_dP\n",
        "    dL_dP = -self.Y / self.P\n",
        "    return dL_dP"
      ],
      "metadata": {
        "id": "SzsqlGxXxpON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2\n",
        "##### Using the sklearn.load boston() function, obtain boston house pricing dataset. Train a regression model using the operations implemented above. You need to write a stochastic gradient descent function to train."
      ],
      "metadata": {
        "id": "b9Rr6hLGxij9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "X, Y = load_boston(return_X_y = True) #return_X_y: If set to True, returns (data, target)"
      ],
      "metadata": {
        "id": "FU6QU7ilxfYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stochastic_gradient_descent(X, Y, lr, num_of_iterations):\n",
        "  Y= np.array([[i] for i in Y])\n",
        "  loss_values = []\n",
        "\n",
        "  #defining the model\n",
        "  layer1 = matrix_multiplication_layer(1, len(X[0]))\n",
        "  layer2 = bias_addition_layer(1)\n",
        "  layer3 = mse_layer()\n",
        "\n",
        "  def model_forward_pass(curr_training_input, curr_training_label):\n",
        "    # forward pass in model\n",
        "      N = layer1.forward_pass(curr_training_input) #N = XW\n",
        "      P = layer2.forward_pass(N) #P = N + B where P is the model prediction\n",
        "      L = layer3.forward_pass(P, curr_training_label)\n",
        "      return P, L\n",
        "\n",
        "  # training the model\n",
        "  for iter in range(num_of_iterations):\n",
        "    for j in range(len(X)): # taking each sample one by one\n",
        "      curr_training_input = np.array([X[j]])\n",
        "      curr_training_label = Y[j]\n",
        "\n",
        "      model_forward_pass(curr_training_input, curr_training_label)\n",
        "\n",
        "      #backward pass in model and updating the weights and bias along the way\n",
        "      dL_dP = layer3.backward_pass()\n",
        "      dL_dN = layer2.backward_pass(dL_dP)\n",
        "      dL_dX = layer1.backward_pass(dL_dN)\n",
        "    \n",
        "    #calculating the overall loss after updation of weights\n",
        "    _, L = model_forward_pass(X, Y)\n",
        "    loss_values.append(L[0][0])\n",
        "\n",
        "    if iter % (num_of_iterations / 20) == 0:\n",
        "      print(\"Current iteration =\", iter)\n",
        "  print(\"Training done.\")\n",
        "\n",
        "  return loss_values"
      ],
      "metadata": {
        "id": "CIYceZuv9FGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values = stochastic_gradient_descent(X, Y, 0.01, 2000)\n",
        "plt.scatter(range(len(loss_values)),loss_values)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "kSSA_Fjy9TVy",
        "outputId": "aa021a21-3450-46de-f0e6-4256248a0aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current iteration = 0\n",
            "Current iteration = 100\n",
            "Current iteration = 200\n",
            "Current iteration = 300\n",
            "Current iteration = 400\n",
            "Current iteration = 500\n",
            "Current iteration = 600\n",
            "Current iteration = 700\n",
            "Current iteration = 800\n",
            "Current iteration = 900\n",
            "Current iteration = 1000\n",
            "Current iteration = 1100\n",
            "Current iteration = 1200\n",
            "Current iteration = 1300\n",
            "Current iteration = 1400\n",
            "Current iteration = 1500\n",
            "Current iteration = 1600\n",
            "Current iteration = 1700\n",
            "Current iteration = 1800\n",
            "Current iteration = 1900\n",
            "Training done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3\n",
        "##### Load the iris dataset in sklearn. This data sets consists of 3 different types of irisesâ€™ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray. Using the operations implemented above create a multi-class classifier (Cross entropy loss + soft max)"
      ],
      "metadata": {
        "id": "uNVxyyI1I1_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "X_iris, Y_iris = datasets.load_iris(return_X_y=True) #(training data, label)\n",
        "\n",
        "num_of_labels = 3 # Setosa, Versicolour, and Virginica\n",
        "# one hot encoding on true labels\n",
        "y = np.zeros((len(X_iris), num_of_labels))\n",
        "for i in range(len(X_iris)):\n",
        "  y[i][Y_iris[i]] = 1\n",
        "Y_iris = y"
      ],
      "metadata": {
        "id": "e3_IV15DI25h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_batch_gradient_descent(X, Y, lr, num_of_iterations):\n",
        "  loss_values = [] # to store loss values after each iteration\n",
        "\n",
        "  #defining the model\n",
        "  layer1 = matrix_multiplication_layer(num_of_labels, len(X[0]))\n",
        "  layer2 = bias_addition_layer(num_of_labels)\n",
        "  layer3 = softmax_layer()\n",
        "  layer4 = cross_entropy_loss_layer()\n",
        "\n",
        "  def model_forward_pass():\n",
        "    # forward pass of model and returns the predictions and the loss value\n",
        "    N = layer1.forward_pass(X)\n",
        "    Z = layer2.forward_pass(N)\n",
        "    P = layer3.forward_pass(Z)\n",
        "    L = layer4.forward_pass(P, Y)\n",
        "    return P, L # returns prediction and loss\n",
        "\n",
        "  def model_backward_pass():\n",
        "    # updating weights and biases\n",
        "    dL_dP = layer4.backward_pass()\n",
        "    dL_dZ = layer3.backward_pass(dL_dP)\n",
        "    dL_dN = layer2.backward_pass(dL_dZ)\n",
        "    dL_dX = layer1.backward_pass(dL_dN)\n",
        "\n",
        "  for iter in range(num_of_iterations):\n",
        "    model_forward_pass()\n",
        "    model_backward_pass()\n",
        "    predictions, loss = model_forward_pass() #forward pass after updation of weights and biases\n",
        "    loss_values.append(loss)\n",
        "\n",
        "    if iter % (num_of_iterations / 20) == 0:\n",
        "      print(\"current iteration =\", iter)\n",
        "\n",
        "  #forward pass of model after all the iterations are done\n",
        "  final_predictions, final_loss = model_forward_pass()\n",
        "\n",
        "  # computing model accuracy\n",
        "  correct_predictions = 0\n",
        "  for i in range(len(final_predictions)):\n",
        "    index_of_predicted_value = np.argmax(final_predictions[i])\n",
        "    if Y[i][index_of_predicted_value] == 1:\n",
        "      correct_predictions += 1\n",
        "\n",
        "  print(\"Final accuracy of the model =\", correct_predictions / len(final_predictions))\n",
        "  return loss_values"
      ],
      "metadata": {
        "id": "v6Zf5VYiJEMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values = full_batch_gradient_descent(X_iris, Y_iris, 0.01, 10000)\n",
        "plt.scatter(range(len(loss_values)),loss_values)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YUgsTXQkJEUL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "89d9756b-9b8b-439b-ab9f-f116ca83395a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current iteration = 0\n",
            "current iteration = 500\n",
            "current iteration = 1000\n",
            "current iteration = 1500\n",
            "current iteration = 2000\n",
            "current iteration = 2500\n",
            "current iteration = 3000\n",
            "current iteration = 3500\n",
            "current iteration = 4000\n",
            "current iteration = 4500\n",
            "current iteration = 5000\n",
            "current iteration = 5500\n",
            "current iteration = 6000\n",
            "current iteration = 6500\n",
            "current iteration = 7000\n",
            "current iteration = 7500\n",
            "current iteration = 8000\n",
            "current iteration = 8500\n",
            "current iteration = 9000\n",
            "current iteration = 9500\n",
            "Final accuracy of the model = 0.7066666666666667\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQ-qkXJa8c3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}